# cfg_check_0
exp:
  name: "ctl_rtc_imagenet100_trial3_test"
  load_model_name: ''
  debug: False


# important cfg

# cfg_check_1
# sample_rate & epoch
sample_rate: 0.3    # 0.3 or 0.001
epochs: 2             # 170 or 2
decouple:
  enable: True
  epochs: 2          # 50 or 2
  fullset: False
  lr: 0.05            # 0.05 or 0.025
  scheduling:
    - 15
    - 30
  lr_decay: 0.1
  weight_decay: 0.0005
  temperature: 5.0

# cfg_check_2
# load_prev_model eg. has ckpts/ (decouple_)step13 then set retrain_from_task: 14
retrain_from_task: 0  # 0 or n
save_mem: True
load_mem: False       # False or True

# cfg_check_3
# change seed & dataset
seed: 500              # 500 or 600 or 1993
dataset: "imagenet100" # 'imagenet100' or 'cifar100'
trial: 3               # 3 or 2
# check datasets.py trial2 / trial3 BFS / DFS


# check cgpu_using
check_cgpu_info: True
check_cgpu_batch_period: 30

# cfg_check_4
# change batch_size then change the lr in  decouple
lr: 0.1
batch_size: 128        # 128 or 64
num_workers: 4

save_result_path: '/datasets/imagenet100_results/' # '/datasets/imagenet100_results/' or ''

taxonomy: 'rtc' # rtc for Real Taxonomic Classifier
save_ckpt: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]


# lr_decay
scheduling:
  - 100
  - 120

is_distributed: False


# Model Cfg
model: "incmodel"
model_cls: "hiernet"
model_pivot:
  arch: pivot
  dropout_rate: 0.0
convnet: 'resnet18'  # modified_resnet32, resnet18
#taxonomy: 'rtc' # rtc for Real Taxonomic Classifier
train_head: 'softmax'
infer_head: 'softmax'
channel: 64
use_bias: False
last_relu: False

der: True
use_aux_cls: True
aux_n+1: True
distillation: "none"
temperature: 2

reuse_oldfc: True
weight_normalization: False
val_per_n_epoch: -1 # Validation Per N epoch. -1 means the function is off.
#save_ckpt: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
#save_result_path: '/datasets/imagenet100_results/' # '/datasets/imagenet100_results/' or ''
#check_cgpu_info: True
#check_cgpu_batch_period: 30
#save_mem: True
#load_mem: False

# Optimization; Training related
task_max: 10
lr_min: 0.00005
#lr: 0.1
#num_workers: 4
weight_decay: 0.0005
dynamic_weight_decay: False
scheduler: 'multistep'
#scheduling:
#  - 100
#  - 120
lr_decay: 0.1
optimizer: "sgd"
#epochs: 2
resampling: False
warmup: False
warmup_epochs: 10
#sample_rate: 0.001
#retrain_from_task: 0

train_save_option:
  acc_details: True
  acc_aux_details: True
  preds_details: True
  preds_aux_details: True

postprocessor:
  enable: False
  type: 'bic'  #'bic', 'wa'
  epochs: 1
  batch_size: 128
  lr: 0.1
  scheduling:
    - 60
    - 90
    - 120
  lr_decay_factor: 0.1
  weight_decay: 0.0005


#decouple:
#  enable: True
#  epochs: 2
#  fullset: False
#  lr: 0.05
#  scheduling:
#    - 15
#    - 30
#  lr_decay: 0.1
#  weight_decay: 0.0005
#  temperature: 5.0

pretrain:
  epochs: 200
  lr: 0.1
  scheduling:
    - 60
    - 120
    - 160
  lr_decay: 0.1
  weight_decay: 0.0005


# Dataset Cfg
#dataset: "imagenet100"  # 'imagenet100', 'cifar100'
#trial: 3
increment: 10
#batch_size: 128

validation: 0.1  # Validation split (0. <= x <= 1.)
random_classes: False  # Randomize classes order of increment
start_class: 0  # number of tasks for the first step, start from 0.
start_task: 0
max_task:  # Cap the number of task
#is_distributed: False

# Memory
memory_enable: True
coreset_strategy: "iCaRL"  # iCaRL, random
mem_size_mode: "uniform_fixed_total_mem"  # uniform_fixed_per_cls, uniform_fixed_total_mem
memory_size: 2000  # Max number of storable examplars
fixed_memory_per_cls: 20  # the fixed number of exemplars per cls

# Misc
device_auto_detect: True  # If True, use GPU whenever possible
device: 0 # GPU index to use, for cpu use -1
#seed: 500
overwrite_prevention: False



