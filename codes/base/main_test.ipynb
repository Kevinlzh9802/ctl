{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "306ed4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sparse2coarse(targets):\n",
    "    \"\"\"Convert Pytorch CIFAR100 sparse targets to coarse targets.\n",
    "    Usage:\n",
    "        trainset = torchvision.datasets.CIFAR100(path)\n",
    "        trainset.targets = sparse2coarse(trainset.targets)\n",
    "    \"\"\"\n",
    "    coarse_labels = np.array([ 4,  1, 14,  8,  0,  6,  7,  7, 18,  3,  \n",
    "                               3, 14,  9, 18,  7, 11,  3,  9,  7, 11,\n",
    "                               6, 11,  5, 10,  7,  6, 13, 15,  3, 15,  \n",
    "                               0, 11,  1, 10, 12, 14, 16,  9, 11,  5, \n",
    "                               5, 19,  8,  8, 15, 13, 14, 17, 18, 10, \n",
    "                               16, 4, 17,  4,  2,  0, 17,  4, 18, 17, \n",
    "                               10, 3,  2, 12, 12, 16, 12,  1,  9, 19,  \n",
    "                               2, 10,  0,  1, 16, 12,  9, 13, 15, 13, \n",
    "                              16, 19,  2,  4,  6, 19,  5,  5,  8, 19, \n",
    "                              18,  1,  2, 15,  6,  0, 17,  8, 14, 13])\n",
    "    return coarse_labels[targets]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d12d4932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_591/1299824488.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mcifar100_data_fine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_fine\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR100\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../datasets/cifar100'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcifar100_data_coarse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_coarse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR100\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../datasets/cifar100'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtargets_coarse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse2coarse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets_coarse\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# update labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "cifar100_data_fine = torchvision.datasets.CIFAR100('../../../datasets/cifar100', download=True)\n",
    "cifar100_data_coarse = torchvision.datasets.CIFAR100('../../../datasets/cifar100', download=True)\n",
    "cifar100_data_coarse.targets = sparse2coarse(cifar100_data_coarse.targets)    # update labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2544373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_datasets(dataset_names):\n",
    "    return [get_dataset(dataset_name) for dataset_name in dataset_names.split(\"-\")]\n",
    "\n",
    "\n",
    "def get_dataset(dataset_name):\n",
    "    if dataset_name == \"cifar10\":\n",
    "        return iCIFAR10\n",
    "    elif dataset_name == \"cifar100\":\n",
    "        return iCIFAR100\n",
    "    elif \"imagenet100\" in dataset_name:\n",
    "        return iImageNet100\n",
    "    elif dataset_name == \"imagenet\":\n",
    "        return iImageNet\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown dataset {}.\".format(dataset_name))\n",
    "\n",
    "\n",
    "class DataHandler:\n",
    "\n",
    "    base_dataset = None\n",
    "    train_transforms = []\n",
    "    common_transforms = [ToTensorV2()]\n",
    "    class_order = None\n",
    "\n",
    "    \n",
    "class iCIFAR100(DataHandler):\n",
    "    def __init__():\n",
    "        pass\n",
    "    \n",
    "    label_list = [\n",
    "        'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy',\n",
    "        'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',\n",
    "        'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish',\n",
    "        'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "        'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange',\n",
    "        'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "        'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk',\n",
    "        'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank',\n",
    "        'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale',\n",
    "        'willow_tree', 'wolf', 'woman', 'worm'\n",
    "    ]\n",
    "\n",
    "    \n",
    "def split_data(data_c):\n",
    "    # currently for trees with depth of 2\n",
    "    DataLoaderList = []\n",
    "    tg = data_c.targets.copy()\n",
    "    for class_i in range(len(np.unique(tg))):\n",
    "        DataLoaderList.append(torch.utils.data.DataLoader((data_c.data[tg==tg[class_i]], data_c.targets[tg==tg[class_i]])))\n",
    "    return DataLoaderList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f9d65a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (535748290.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_899/535748290.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    main.py train with \"./configs/1.yaml\" \\\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python -m main train with \"./configs/1.yaml\" \\\n",
    "        exp.name=\"10scifar100_trial0_debug\" \\\n",
    "        exp.savedir=\"./logs/\" \\\n",
    "        exp.ckptdir=\"./logs/\" \\\n",
    "        exp.tensorboard_dir=\"./tensorboard/\" \\\n",
    "        trial=0 \\\n",
    "        --name=\"${name}\" \\\n",
    "        -D \\\n",
    "        -p \\\n",
    "        -c \"${comments}\" \\\n",
    "        --force \\\n",
    "        --mongo_db=10.10.10.100:30620:classil\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cbc24eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f21c10c4700>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1805e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "æ— ",
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
